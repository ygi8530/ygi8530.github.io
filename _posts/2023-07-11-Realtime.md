---
title: Real-time video prediction using gans with guidance information for time-delayed robot teleoperation
date: 2023-07-11 12:00:00 +0900
categories: [paper]
tags: [Computer Vision, Robotic Manipulation, Deep Learning, Video Prediction]     # TAG names should always be lowercase
author: [Kang-il_Yoon, Dae-Kwan_Ko, Soo-Chul_Lim]
description: 'International Journal of Control, Automation and Systems, vol.21, pp.2387–2397, 2023'
toc: true  # 목차 표시 여부 (기본값: true)
comments: true  # 댓글 허용 여부 (기본값: _config.yml 설정 따라감)
pin: true  # 홈 화면에서 상단 고정 (선택 사항)
math: true  # 수학 수식 활성화 (선택 사항)
mermaid: true  # Mermaid 다이어그램 활성화 (선택 사항)
---
<!-- International Journal of Control, Automation and Systems, vol.21, pp.2387–2397, 2023<br> -->
DOI: <a href="https://link.springer.com/article/10.1007/s12555-022-0358-3" target="_blank">10.1007/s12555-022-0358-3</a><br>
<a href="https://link.springer.com/article/10.1007/s12555-022-0358-3" target="_blank">[Paper]</a> &nbsp;&nbsp;
<a href="https://www.youtube.com/watch?v=UgxSEOrBKFo&t=97s&ab_channel=InteractiveRoboticsLab%2CDonggukUniversity" target="_blank">[Video]</a><br>

A deep-learning method for real-time video prediction is proposed that overcomes delays in the transmission of visual information in teleoperation. The proposed method predicts the real-time video frame from a delayed image using guidance information (the current master position and the delayed interaction force) transmitted from the robot. To predict accurate and realistic video frames, adversarial training is introduced. The generator in the GAN is composed of image encoders, a guidance-information embedder, and prediction decoders. To create the training data set, three experimenters remotely operated robots that gripped, picked up, and moved nine objects. Numerical results and predicted images are presented, verifying that the master position and the interaction force can be used effectively to predict the current video frame. The proposed method can reduce time-delay problems in teleoperation systems.